---
title: "p8105_hw6_mx2286"
author: "William Xie"
date: "2024-12-01"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rnoaa)
library(broom)
library(modelr)
library(purrr)
library(knitr)

knitr::opts_chunk$set(echo = TRUE)
```

#Question 1
```{r}
# Pull weather data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

# Bootstrap function
bootstrap_function <- function(data, n_bootstrap = 5000) {
  # Initialize vectors to store results
  r_squared_values <- numeric(n_bootstrap)
  log_beta_product_values <- numeric(n_bootstrap)
  
  for (i in 1:n_bootstrap) {
    # Sample with replacement
    boot_sample <- data %>%
      slice_sample(n = nrow(data), replace = TRUE)
    
    # Perform linear regression
    model <- lm(tmax ~ tmin, data = boot_sample)
    
    # Extract R^2
    r_squared_values[i] <- glance(model)$r.squared
    
    # Extract regression coefficients
    beta_coefficients <- coef(model)
    beta_0 <- beta_coefficients[1]
    beta_1 <- beta_coefficients[2]
    
    # Compute log(β0 * β1), avoiding log(0) or negative issues
    if (!is.na(beta_0 * beta_1) && beta_0 * beta_1 != 0) {
      log_beta_product_values[i] <- log(abs(beta_0 * beta_1))
    } else {
      log_beta_product_values[i] <- NA
    }
  }
  
  return(list(r_squared = r_squared_values, log_beta_product = log_beta_product_values))
}

# Set seed for reproducibility
set.seed(123)

# Perform bootstrapping
bootstrap_results <- bootstrap_function(weather_df)

# Extract results
r_squared_values <- bootstrap_results$r_squared
log_beta_product_values <- bootstrap_results$log_beta_product

# Compute confidence intervals
r_squared_ci <- quantile(r_squared_values, probs = c(0.025, 0.975), na.rm = TRUE)
log_beta_product_ci <- quantile(log_beta_product_values, probs = c(0.025, 0.975), na.rm = TRUE)

# Print confidence intervals
print(paste("R-squared 95% CI:", paste(round(r_squared_ci, 3), collapse = " - ")))
print(paste("log(β0 * β1) 95% CI:", paste(round(log_beta_product_ci, 3), collapse = " - ")))

# Plot distribution of R-squared values
ggplot(data.frame(r_squared = r_squared_values), aes(x = r_squared)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Bootstrap Distribution of R-squared", x = "R-squared", y = "Frequency")

# Plot distribution of log(β0 * β1) values
ggplot(data.frame(log_beta_product = log_beta_product_values), aes(x = log_beta_product)) +
  geom_histogram(binwidth = 0.05, fill = "red", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Bootstrap Distribution of log(β0 * β1)", x = "log(β0 * β1)", y = "Frequency")
```
```{r}
homicide_data <- read.csv("homicide-data.csv")
head(homicide_data)
```


#Question 2
```{r}
# Create a dummy variable 'resolved' based on the 'disposition' column
homicide_data <- homicide_data %>%
  mutate(resolved = ifelse(disposition %in% c("Closed without arrest", "Closed by arrest"), 1, 0))
head(homicide_data)

```

```{r}
homicide_data <- read.csv("homicide-data.csv") %>%
  mutate(
    resolved = ifelse(disposition %in% c("Closed without arrest", "Closed by arrest"), 1, 0),
    victim_age = as.numeric(victim_age),
    city_state = paste(city, state, sep = ", ")
  ) %>%
  filter(victim_race %in% c("White", "Black"), 
         !city %in% c("Dallas", "Tulsa"))

baltimore_data <- homicide_data %>%
  filter(city_state == "Baltimore, MD")

model_baltimore <- glm(resolved ~ victim_age + victim_sex + victim_race, 
                       data = baltimore_data, 
                       family = binomial)

summary_baltimore <- broom::tidy(model_baltimore, exponentiate = TRUE, conf.int = TRUE)
print(summary_baltimore)

nested_data <- homicide_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(data = map(data, ~filter(.x, !is.na(victim_age) & !is.na(victim_sex) & !is.na(victim_race))))

city_models <- nested_data %>%
  mutate(
    model = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial)),
    results = map(model, ~broom::tidy(.x, exponentiate = TRUE, conf.int = TRUE))
  ) %>%
  unnest(results)

odds_ratios <- city_models %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high)

ggplot(odds_ratios, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "The odds of solving crimes for male victims and female victims in each city",
       x = "Cities",
       y = "Odds ratio (OR) and confidence interval") +
  theme_minimal(base_size = 8)

odds_ratios <- odds_ratios %>%
  arrange(desc(estimate))

head(odds_ratios)
```
The OR of 1.129 in Fresno, CA, suggests that cases involving male victims are more likely to be solved compared to those involving female victims. However, the confidence interval of 0.454–2.648 includes 1, indicating that this difference is not statistically significant. Similarly, in Minneapolis, MN, and Stockton, CA, the ORs point to a potential advantage for male victims, but the broad confidence intervals weaken the certainty of these results.


#Question 3
```{r}
# Load and preprocess the dataset
birthweight_clean <- read_csv("birthweight.csv") %>%
  mutate(
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
    ),
    frace = case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown"
    ),
    babysex = case_when(
      babysex == 1 ~ "Male",
      babysex == 2 ~ "Female"
    ),
    blength = as.numeric(blength),
    bhead = as.numeric(bhead),
    gaweeks = as.numeric(gaweeks),
    ppwt = as.numeric(ppwt),
    wtgain = as.numeric(wtgain)
  ) %>%
  drop_na()

# Check dataset summary
summary(birthweight_clean)
```
##Proposed Regression Model

The first model posits that birthweight is determined by *gestational age* , *maternal pre-pregnancy weight* , and *birth length* , as well as an interaction between gaweeks and blength.
```{r}
# Fit the proposed model
proposed_model <- lm(bwt ~ babysex + gaweeks + ppwt + blength + blength:gaweeks, data = birthweight_clean)

# Summarize the proposed model
proposed_model_summary <- broom::tidy(proposed_model) %>%
  mutate(
    OR = exp(estimate),
    CI_upper = exp(estimate + 1.96 * std.error),
    CI_lower = exp(estimate - 1.96 * std.error)
  ) %>%
  select(term, estimate, OR, CI_lower, CI_upper, p.value)

# Display the summary as a table
proposed_model_summary %>%
  kable(digits = 3, caption = "Proposed Model Summary")
```
```{r}
# Add residuals and predictions
proposed_results <- birthweight_clean %>%
  mutate(
    pred = predict(proposed_model, newdata = birthweight_clean),
    resid = residuals(proposed_model)
  )

# Plot residuals vs fitted values
ggplot(proposed_results, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Proposed Model)",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()

```
The residual plot displayed acceptable dispersion with slight heteroscedasticity at higher fitted values, suggesting room for improvement while demonstrating adequate predictive performance across most of the data range.

# Model 2: Birth Length and Gestational Age
```{r}
model_2 <- lm(bwt ~ blength + gaweeks, data = birthweight_clean)

ggplot(birthweight_clean %>% 
         mutate(resid = residuals(model_2), pred = predict(model_2)), aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Residuals vs Fitted Values (Model 2)",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()
```
The residuals showed greater dispersion around the fitted values compared to the proposed model, suggesting less accurate predictions.

# Model 3: Head Circumference, Length, and Baby’s Sex with Interactions
```{r}
model_3 <- lm(bwt ~ bhead * blength * babysex, data = birthweight_clean)

ggplot(birthweight_clean %>% 
         mutate(resid = residuals(model_3), pred = predict(model_3)), aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Residuals vs Fitted Values (Model 3)",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()
```
The residuals formed a tighter cluster, indicating a better model fit compared to Model 2, although it did not definitively surpass the performance of the proposed model.

# Cross-Validation
```{r}
cv_results <- crossv_mc(birthweight_clean, n = 100, test = 0.2) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    proposed_model = map(train, ~ lm(bwt ~ babysex + gaweeks + ppwt + blength + blength:gaweeks, data = .x)),
    model_2 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    model_3 = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    rmse_proposed = map2_dbl(proposed_model, test, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - preds)^2))
    }),
    rmse_model_2 = map2_dbl(model_2, test, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - preds)^2))
    }),
    rmse_model_3 = map2_dbl(model_3, test, ~ {
      preds <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - preds)^2))
    })
  )

# Prepare cv_summary for plotting
cv_summary <- cv_results |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |>
  mutate(model = factor(model, levels = c("proposed", "model_2", "model_3")))

# Plot RMSE comparison
ggplot(cv_summary, aes(x = model, y = rmse, fill = model)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) + 
  geom_jitter(width = 0.2, alpha = 0.5, color = "black") + 
  scale_fill_manual(values = c("lightgreen", "salmon", "skyblue")) + 
  labs(
    title = "Cross-Validation RMSE Comparison",
    x = "Model",
    y = "RMSE",
    fill = "Model"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

The RMSE comparison revealed that Model 3 had the lowest median RMSE (~310) and the least variation, indicating its superior predictive performance, likely due to the inclusion of interaction terms. The proposed model demonstrated a median RMSE of ~330, consistently outperforming Model 2 (median RMSE ~350), but it fell slightly short of Model 3 in accuracy. These findings, visualized in a boxplot, highlight the proposed model's reliability while underscoring the enhanced predictive power of interaction effects in Model 3.